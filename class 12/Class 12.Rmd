---
title: 'Class 12: RNASeq Analysis'
author: "Iman Syed a18596789"
date: "2025-11-06"
output: html_document
toc: true
---

##Background
today we will analyze some RNASeq from Himes et.al on the effects of a common steriod(dexamethasone) on airway smooth mucsle cells.

Our starting point is the "counts" data and meta data that contain the count values for each gene in their different experiements.

##Data import

```{r}
# Complete the missing code
counts <- read.csv("airway_scaledcounts.csv", row.names=1)
metadata <-  read.csv("airway_metadata.csv")

```

```{r}
head(counts)


```

#Q1.a how many genes are in this database?

```{r}
nrow(counts)
```

#Q1.b How many different experiments (columns in counts or rows in metadata) are there?

```{r}
ncol(counts)

metadata
```


#Q2 How many 'control' cell lines do we have?

```{r}
sum( metadata$dex == "control")
```

##4. Toy differential gene expression

To start our analysis lets calculate the mean counts for all genes in the control experiements


1. Extract all control columns from the counts object

2. Calculate the mean for all rows (i.e genes) of these "control" columns
3-4. Do the same for "treated"
5. compare these 'control.mean' and 'treated.mean' values.


In the lab manual we are give this chunk of code: 
```{r}
library(dplyr)
control <- metadata %>% filter(dex=="control")
control.counts <- counts %>% select(control$id) 
control.mean <- rowSums(control.counts)/4
head(control.mean)
```


#Q3 How would you make the above code in either approach more robust? is there a function that could help here?

Instead of using `rowSums` and using a long equation, we can use rowMeans()

```{r}
#library(dplyr) don't have to load library again!
control <- metadata %>% filter(dex=="control")
control.counts <- counts %>% select(control$id) 
control.mean <- rowMeans(control.counts)
head(control.mean)

```






The control columns have been extracted here:

```{r}

control.inds <- metadata$dex == "control" 
control.counts <- counts [ , control.inds]


```
2.Calculate the mean for all rows (i.e genes) of these "control" columns

```{r}
control.means <- rowMeans(control.counts)
```


3-4. Do the same for "treated"

#Q4 Follow the same procedure for the treated samples (i.e. calculate the mean per gene across drug treated samples and assign to a labeled vector called treated.mean)

```{r}
treated.inds <- metadata$dex == "treated" 

```


```{r}
treated.counts <- counts [ , treated.inds]

```

```{r}
treated.means <- rowMeans(treated.counts)
```


#store these together for book keeping

```{r}
meancounts <- data.frame(control.means, treated.means)

head(meancounts)
```
#Q5 (a). Create a scatter plot showing the mean of the treated samples against the mean of the control samples. Your plot should look something like the following.

```{r}
plot(meancounts)
```

According to this plot- it seems all the points have been overplotted, and it is highly skewed. Let ammend the data using log transformations

#Q6. Try plotting both axes on a log scale. What is the argument to plot() that allows you to do this? 


```{r}
plot(meancounts, log = "xy")


```
#Q5 (b).You could also use the ggplot2 package to make this figure producing the plot below. What geom_?() function would you use for this plot?

```{r}
library(ggplot2)

ggplot(meancounts, aes(x= control.means, y=treated.means))+
  geom_point(color = "pink", alpha= 0.4, size= 1)+
  labs(x= "control", y= "treated")

```



Much better! :D

We often talk metrics like "log2 fold-change"

```{r}
#control/ treated

log2(10/10)
```


```{r}
log2(10/20)
```



```{r}
log2(20/10)
```
```{r}
log2(10/40)
log2(40/10)

```

Let's calculate log2 fold change for our treated over control mean counts:

```{r}


meancounts$log2fc <- log2(meancounts$treated.means /
  meancounts$control.means)
```



```{r}
head(meancounts)
```




#Q7. What is the purpose of the arr.ind argument in the which() function call above? Why would we then take the first column of the output and need to call the unique() function?

```{r}
zero.vals <- which(meancounts[,1:2]==0, arr.ind=TRUE)

to.rm <- unique(zero.vals[,1])
mycounts <- meancounts[-to.rm,]
head(mycounts)
```

The arr.ind=TRUE argument will clause which() to return both the row and column indices (i.e. positions) where there are TRUE values. In this case this will tell us which genes (rows) and samples (columns) have zero counts. 




A common rule of thumb is a log2 fold change cutoff +2 and -2 to call genes "Up regulated" or "Down regulated". 

Number of "up genes"

#Q8. Using the up.ind vector above can you determine how many up regulated genes we have at the greater than 2 fc level? 

```{r}
sum(meancounts$log2fc >= +2, na.rm = T)
```
#Q9. Using the down.ind vector above can you determine how many down regulated genes we have at the greater than 2 fc level? 

Number of down genes


```{r}
sum(meancounts$log2fc >= -2, na.rm = T)
```

#Q10. Do you trust these results? Why or why not?

No I do not trust these results because all our analysis has been done based on fold change. However, fold change can be large  without being statistically significant (e.g. based on p-values). We have not done anything yet to determine whether the differences we are seeing are significant. These results in their current form are likely to be very misleading.



##DESeq analysis

```{r, message =FALSE}
library(DESeq2)
```



for deseq analysis we need 3 things

-count values 'contData`
-metadata telling us about the columns in 'countData' ('colData')
-design of the experiement (what do you want to compare)

Our first function from DESeq2 will setup thr input required for analysis by storing all these things together:

```{r}
dds <- DESeqDataSetFromMatrix(countData=counts, 
                              colData=metadata, 
                              design=~dex)
dds
```



The main function in DESeq2 that runs the analysis is called "DESeq()"

```{r}
dds <- DESeq(dds)

```

```{r}
res <- results(dds)

head(res)
```

```{r}
36000* 0.05
```

##Volcano summary plot

this is a common summary figure from these types of experiements and plot the log2 fold-change vs the adjusted p-value

##Save your results

```{r}
plot(res$log2FoldChange, -log(res$padj))
abline(v=c(-2,2), col= "pink")
abline(h= -log(0.04), col+ "lightblue")
```


To color the points we will setup a custom color vector indicating transcripts with large fold change and significant differences between conditions:

```{r}
# Setup our custom point color vector 
mycols <- rep("gray", nrow(res))
mycols[ abs(res$log2FoldChange) > 2 ]  <- "red" 

inds <- (res$padj < 0.01) & (abs(res$log2FoldChange) > 2 )
mycols[ inds ] <- "blue"

# Volcano plot with custom colors 
plot( res$log2FoldChange,  -log(res$padj), 
 col=mycols, ylab="-Log(P-value)", xlab="Log2(FoldChange)" )

# Cut-off lines
abline(v=c(-2,2), col="gray", lty=2)
abline(h=-log(0.1), col="gray", lty=2)
```


For even more customization you might find the EnhancedVolcano bioconductor package useful (Note. It uses ggplot under the hood):

First we will add the more understandable gene symbol names to our full results object res as we will use this to label the most interesting genes in our final plot.

```{r}
#BiocManager::install("EnhancedVolcano")

library(EnhancedVolcano)

x <- as.data.frame(res)

EnhancedVolcano(x,
    lab = x$symbol,
    x = 'log2FoldChange',
    y = 'pvalue')
```



```{r}
write.csv(res, file "my_results.csv")
```



##Add gene annotation(second part of lab)

To help make sense of our results and communicate them to toher folks we need to add some more annotation to our main ' res' object.

We will use two bioconductor packages to first map IDs to different formats including the classic gene "symbol" gene name.

BicManager::install("AnnotationDbi")
BicManager::install("org.Hs.eg.db")

```{r}


library(AnnotationDbi)
library(org.Hs.eg.db)

```



let's see what is 'org.Hs.eg.db' with the columns() function

```{r}
columns(org.Hs.eq.db)

```

We can translate or "map" id's between any of these 26 databases using the 'mapIDs()' function

```{r}
res$symbol  <-mapIDs(keys= row.names(res), #our current IDs
                     keytype= "ENSEMBL",  #the format of our IDs
                     x= org.Hs.eg.db,     #where to get the mappings from
                     column = "SYMBOL")   #the format/DB to map to

head(res)



```

Add the mappings for "GENENAME" and "ENTREZID" and store as 'res$genename' and 'res$entrez'

```{r}
res$entrez <- mapIDs(keys= row.names(res), #our current IDs
                     keytype= "ENSEMBL",  #the format of our IDs
                     x= org.Hs.eg.db,     #where to get the mappings from
                     column = "ENTREZID")   #the format/DB to map to
```




##Pathway analysis


There are lots of bioconductor packages to do this type of analysis. For now let's try one called **gage** again we need to install this if we don't have it already.

```{r, message=FALSE}
library(gage)
library(gageData)
library(pathview)
```

To use **gage** I need two things 
- a named vector offold-change valuses for our DEGs (our genes of interest)
- a set of pathways or genesets to use for annotation.

```{r}

x <- c("barry" = 5, "lisa"= 10)

x



```



```{r}
names(x) <- c("low","high") 

x
```


```{r}
foldchanges <- res$log2FoldChange
names(foldchanges) <- res$symbol

head(foldchanges)
```



```{r}
data(kegg.sets.hs)

keggres= gage(foldchanges,gssets= kegg.set.hs)
```


In our results object:

```{r}
attributes(keggres)
```



```{r}

head(keggres$less, 5 )

```


Let's look at one of these pathways with our genes colored up so we can see the overlap

```{r}
pathview(pathway.id = "hsa05310", gene.data= foldchanges)
```


Add this pathway fugure to our lab report
#should be an image here

![](hsa05310.pathview.png) 






Save main results 


```{r}
write.csv(res, file = "myresults_annotated.csv")
```

































































